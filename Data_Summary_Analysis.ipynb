{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surfscan Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: This code provides a temporary solution for interpretation of Surfscan summary output files. As is, the Surfscan files may be hard to intepret and provides unnecessary information for operations. Our goal is to be able to parse these text files and provide a digestible output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#First, Downloading all of the necessary packages\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m Series, DataFrame\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "#First, Downloading all of the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python310\\python.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#!{sys.executable} -m pip install --upgrade pip\n",
    "#Magical code to install packages you don't have already\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python310\\python.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#First, we will try to convert the text file into a csv file that we can begin to manipulate\n",
    "file_path = r'C:\\Users\\anhtu\\Desktop\\Wafer Particles\\Wafer-Particles\\Summary_TXT_Files\\ZZBARESI_HT_20221013_1657.txt'\n",
    "df = pd.read_csv(file_path, encoding= 'unicode_escape')\n",
    "\n",
    "#Adding a column name so that it is easier to call out. The column header had spaces.\n",
    "df.columns=['Parse1']\n",
    "#Removing the separation dashes\n",
    "df= df[df.Parse1 !='--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------']\n",
    "\n",
    "\n",
    "#Trying to clean up the file and the unecessary spaces using two steps\n",
    "#STEP 1: Trimming space from the ends of each values\n",
    "#Let's define what it means to trim the dataframe of unecessary spaces\n",
    "def trim_all_columns(df):\n",
    "    #Trim whitespace from ends of each value across all series in dataframe\n",
    "    trim_strings = lambda x: x.strip() if isinstance(x, str) else x\n",
    "    return df.applymap(trim_strings)\n",
    "\n",
    "#Now, let's utilize our trim definition for our dataframe\n",
    "df = trim_all_columns(df)\n",
    "\n",
    "#STEP2: Replacing every all greater that 1 space [' +'] with 1 space [' ']. Reason for this is so we can split the df by space\n",
    "df = df['Parse1'].str.replace(' +',' ', regex = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python310\\python.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Here, we split the df by space. We are creating a total of 23 columns, therefore we use number 22 because (0,1,2,3,...,22)\n",
    "df = df.str.split(' ',22, expand=True)\n",
    "\n",
    "#Adding proper column headers \n",
    "df.columns = ['Side','WaferID','Grade','Source/Destination','All','Lpd','LpdN',\n",
    "    'LpsED','uScr','Scr','Slip','Area','Avg','Median','STDV','Bin1','Bin2','Bin3',\n",
    "    'Bin4','Bin5','Bin6','Bin7','Bin8'] \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python310\\python.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Here, we identify the index of the row we want to stop\n",
    "#We want to stop the code when the 'WaferID' column reads 'wafer(s)'\n",
    "row = df[df['WaferID'] == 'wafer(s)'].index.tolist()[0]\n",
    "\n",
    "#Keeping only the rows ip to the row we identfied\n",
    "df = df.iloc[:row-3]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have have filtered to the DCO data that we are interested in, it is time to continue parsing the dataframe to extract relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python310\\python.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Deleting some irrelavent columns\n",
    "del df['Side']\n",
    "del df['LpdN']\n",
    "del df['LpsED']\n",
    "del df['uScr']\n",
    "del df['Scr']\n",
    "del df['Slip']\n",
    "del df['Area']\n",
    "del df['Avg']\n",
    "del df['Median']\n",
    "del df['STDV']\n",
    "\n",
    "df.drop([4,5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python310\\python.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Playing with extracting information from the file name itself. \n",
    "x= 'name_of_txt_file.txt'\n",
    "\n",
    "#removing the last 4 characters (which is the '.txt') of the file name\n",
    "x= x[:-4]\n",
    "\n",
    "#splitting the file name separacted by underscore\n",
    "y= x.split('_')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python310\\python.exe' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
