{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install --upgrade pip\n",
    "#Code to install packages you don't have already\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading all of the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import plotly.express as px\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data_Summary_Analysis is running.\")\n",
    "\n",
    "# Converts the text file into a csv file\n",
    "df = pd.read_csv(file_path, encoding= 'unicode_escape')\n",
    "\n",
    "#Adding a column name so that it is easier to call out. The column header had spaces.\n",
    "df.columns=['Parse1']\n",
    "#Removing the separation dashes\n",
    "df= df[df.Parse1 !='--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------']\n",
    "\n",
    "\n",
    "#Trying to clean up the file and the unecessary spaces using two steps\n",
    "#STEP 1: Trimming space from the ends of each values\n",
    "def trim_all_columns(df):\n",
    "    #Trim whitespace from ends of each value across all series in dataframe\n",
    "    trim_strings = lambda x: x.strip() if isinstance(x, str) else x\n",
    "    return df.applymap(trim_strings)\n",
    "\n",
    "#Utilize our trim definition for our dataframe\n",
    "df = trim_all_columns(df)\n",
    "\n",
    "#STEP2: Replacing every all greater that 1 space [' +'] with 1 space [' ']. Reason for this is so we can split the df by space\n",
    "df = df['Parse1'].str.replace(' +',' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the df by space. We are creating a total of 23 columns, therefore we use number 22 because (0,1,2,3,...,22)\n",
    "df = df.str.split(' ', n = 22, expand=True)\n",
    "\n",
    "#Adding proper column headers \n",
    "df.columns = ['Side','Grade','Source/Destination','All','Lpd','LpdN',\n",
    "    'LpsED','uScr','Scr','Slip','Area (#)','Area (mm^2)','Avg','Median','STDV','Bin1','Bin2','Bin3',\n",
    "    'Bin4','Bin5','Bin6','Bin7','Bin8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the index of the row we want to stop\n",
    "#We want to stop the code when the 'WaferID' column reads 'wafer(s)'\n",
    "row = df[df['Grade'] == 'wafer(s)'].index.tolist()[0]\n",
    "\n",
    "#Keeping only the rows ip to the row we identfied\n",
    "df = df.iloc[:row-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting irrelavent columns\n",
    "del df['LpdN']\n",
    "del df['LpsED']\n",
    "del df['uScr']\n",
    "del df['Scr']\n",
    "del df['Slip']\n",
    "del df['Area (#)']\n",
    "del df['Area (mm^2)']\n",
    "del df['Avg']\n",
    "del df['Median']\n",
    "del df['STDV']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes extension from file name\n",
    "fileName = Path(file_path).stem\n",
    "\n",
    "# Extracts date and time from file name\n",
    "fileTitle = ''.join(i for i in fileName if i.isdigit())\n",
    "\n",
    "# Iterates through number string backward to isolate date and time\n",
    "dateTime = \"\"\n",
    "counter = 0\n",
    "for character in fileTitle[::-1]:\n",
    "    if counter <= 11:\n",
    "        dateTime = \"\".join([dateTime, character])\n",
    "        counter += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "dateTime = dateTime[::-1]\n",
    "\n",
    "date = dateTime[0:8]\n",
    "\n",
    "time = dateTime[8:]\n",
    "\n",
    "# Extracts session from dataframe\n",
    "a = df.iloc[0]['Grade']\n",
    "b = df.iloc[0]['Source/Destination']\n",
    "c = df.iloc[0]['All']\n",
    "\n",
    "# Filter for session separated by a space\n",
    "if b != None and c != None:\n",
    "    session = \" \".join([a, b, c])\n",
    "elif b != None:\n",
    "    session = \" \".join([a, b])\n",
    "else:\n",
    "    session = a\n",
    "\n",
    "# Extracts Lot ID from dataframe\n",
    "a = df.iloc[1]['Source/Destination']\n",
    "\n",
    "# Filter for lot ID separated by a space\n",
    "b = df.iloc[1]['All']\n",
    "if b == None:\n",
    "    lotID = a\n",
    "else:\n",
    "    lotID = \" \".join([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds additional columns to dataframe\n",
    "df = df.assign(\n",
    "    Session = lambda x: session,\n",
    "    Lot_ID = lambda x: lotID,\n",
    "    Date = lambda x: date,\n",
    "    Time = lambda x: time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes irrelevant rows\n",
    "df = df.drop(df[df.Side != 'F'].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports table as an excel file\n",
    "df.to_csv(f'../../Wafer-Particles-main/Wafer-Particles-main/Parsed_Output/{fileName}.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
